{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from dataclasses import dataclass\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "import pytesseract\n",
    "import re\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Configuration:\n",
    "    cities: tuple = ('Birmingham', 'Chester', 'Dublin', 'Edinburgh', \n",
    "                     'Exeter', 'Glasgow', 'London', 'Newcastle', 'Sheffield')\n",
    "    letters: tuple = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
    "                      'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z')\n",
    "    russian: tuple = ('1896-1908', 'before1896', 'from1908')\n",
    "    \n",
    "\n",
    "    hallmark_image_shape: tuple = (70, 70)\n",
    "    letter_image_shape: tuple = (70, 70)\n",
    "    russian_image_shape: tuple = (100, 100)\n",
    "\n",
    "    path_to_letter_model_weights: str = 'configuration/letter_classification.pth'\n",
    "    path_to_city_model_weights: str = 'configuration/city_classification.pth'\n",
    "    path_to_russian_model_weights: str = 'configuration/russian_classification.pth'\n",
    "\n",
    "    path_to_detection_model_weights: str = 'configuration/yolov4-obj.weights'\n",
    "    path_to_detection_config_file: str = 'configuration/yolov4-obj.cfg'\n",
    "\n",
    "    # Name of the classes for detection\n",
    "    with open(\"configuration/classes.txt\") as f:\n",
    "        class_names = [line.strip() for line in f]\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def init_resnet_model(config: dataclass, path_to_weights: str) -> models.ResNet:\n",
    "    \"\"\"\n",
    "    The function return object of model with uploaded weights for certain task of classification\n",
    "\n",
    "\n",
    "    :param config: dataclass object with all necessary information\n",
    "    :param path_to_weights: path to .pth file with weights of model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    device = config.device\n",
    "    model_state = torch.load(path_to_weights, map_location=torch.device(device))\n",
    "    output_number_of_classes, input_number_of_features = model_state['fc.weight'].shape\n",
    "\n",
    "    # Model architecture initialization\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    model.fc = torch.nn.Linear(input_number_of_features, output_number_of_classes)\n",
    "\n",
    "    # Loading state of the model\n",
    "    model.load_state_dict(model_state)\n",
    "\n",
    "    # Transferring the model to the device and freezing the weights\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def init_squeezenet_model(config: dataclass, path_to_weights: str) -> models.SqueezeNet:\n",
    "    \"\"\"\n",
    "    The function return object of model with uploaded weights for certain task of classification\n",
    "\n",
    "\n",
    "    :param config: dataclass object with all necessary information\n",
    "    :param path_to_weights: path to .pth file with weights of model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    device = config.device\n",
    "    model_state = torch.load(path_to_weights, map_location=torch.device(device))\n",
    "#     output_number_of_classes, input_number_of_features = model_state['fc.weight'].shape\n",
    "    output_number_of_classes, input_number_of_features = model_state.classifier[1].weight.shape[0], model_state.classifier[1].weight.shape[1]\n",
    "\n",
    "    # Model architecture initialization\n",
    "    model = models.squeezenet1_1(pretrained=False)\n",
    "    model.classifier[1] = nn.Conv2d(input_number_of_features, output_number_of_classes, kernel_size=(1,1), stride=(1,1))\n",
    "\n",
    "    # Loading state of the model\n",
    "    model.load_state_dict(model_state.state_dict())\n",
    "\n",
    "    # Transferring the model to the device and freezing the weights\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def init_detection_model(config: dataclass) -> cv2.dnn_DetectionModel:\n",
    "    \"\"\"\n",
    "    The function return object of model with uploaded weights for detection task\n",
    "    :param config: dataclass object with all necessary information\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    path_to_weights = config.path_to_detection_model_weights\n",
    "    path_to_config = config.path_to_detection_config_file\n",
    "\n",
    "    net = cv2.dnn.readNet(path_to_weights, path_to_config)\n",
    "    net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "    net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA_FP16)\n",
    "\n",
    "    model = cv2.dnn_DetectionModel(net)\n",
    "    model.setInputParams(size=(416, 416), scale=1 / 255, swapRB=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def image_to_gray(img):\n",
    "    gray = cv2.resize(img, None, fx = 5, fy = 5, interpolation = cv2.INTER_CUBIC)\n",
    "    rect_kern = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    dilation = cv2.dilate(gray, rect_kern, iterations = 1)\n",
    "\n",
    "    return dilation\n",
    "\n",
    "def predict_year(im):\n",
    "    gray =  cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    h, w = gray.shape\n",
    "    if h/w > 1: \n",
    "        gray = cv2.rotate(gray, cv2.cv2.ROTATE_90_CLOCKWISE)\n",
    "        im = cv2.rotate(im, cv2.cv2.ROTATE_90_CLOCKWISE)\n",
    "    \n",
    "    gray = cv2.resize( gray, None, fx = 3, fy = 3, interpolation = cv2.INTER_CUBIC)\n",
    "    im = cv2.resize(im, None, fx = 3, fy = 3, interpolation = cv2.INTER_CUBIC)\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "    gray = cv2.medianBlur(gray, 3)\n",
    "    ret, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY)\n",
    "\n",
    "    rect_kern = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    dilation = cv2.dilate(thresh, rect_kern, iterations = 1)\n",
    "\n",
    "    # find contours\n",
    "    try:\n",
    "        contours, hierarchy = cv2.findContours(dilation, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    except:\n",
    "        ret_img, contours, hierarchy = cv2.findContours(dilation, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    sorted_contours = sorted(contours, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "\n",
    "    # create copy of image\n",
    "    im2 = dilation.copy()\n",
    "    height, width = im2.shape\n",
    "\n",
    "    year = \"\"\n",
    "\n",
    "    color = (0,215,255)\n",
    "    # loop through contours and find letters in license plate\n",
    "    for cnt in sorted_contours:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "\n",
    "        if height / float(h) > 3: continue\n",
    "        ratio = h / float(w)\n",
    "        if ratio < 1.25: continue\n",
    "        area = h * w\n",
    "        if width / float(w) > 20: continue\n",
    "        if area < 100: continue\n",
    "            \n",
    "        # draw the rectangle\n",
    "        rect = cv2.rectangle(im, (x,y), (x+w, y+h), color,2)\n",
    "        padding = 0\n",
    "        roi = thresh[y-padding:y+h+padding, x-padding:x+w+padding]\n",
    "        roi = cv2.bitwise_not(roi)\n",
    "        roi = cv2.medianBlur(roi, 5)\n",
    "\n",
    "        text = pytesseract.image_to_string(roi, config='-c tessedit_char_whitelist=0123456789 --psm 8 --oem 3')\n",
    "        clean_text = re.sub('[\\W_]+', '', text)\n",
    "        year += clean_text\n",
    "        \n",
    "    return year\n",
    "\n",
    "class HallmarkAnalyser:\n",
    "    def __init__(self, config: dataclass):\n",
    "        \"\"\"\n",
    "\n",
    "        :param config: class with all configuration parameters\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.device = config.device\n",
    "\n",
    "        # Initialization of all necessary models\n",
    "        self.letter_model = init_resnet_model(config, config.path_to_letter_model_weights)\n",
    "        self.city_model = init_squeezenet_model(config, config.path_to_city_model_weights)\n",
    "        self.russian_model = init_squeezenet_model(config, config.path_to_russian_model_weights)\n",
    "        self.detection_model = init_detection_model(config)\n",
    "\n",
    "        # Detection parameters\n",
    "        self.detection_threshold = 0.2\n",
    "        self.nms_threshold = 0.4\n",
    "        self.colors = ((0,241,255), (0,114,255), (255, 0,241), (14,0,255), (255,0,114))\n",
    "\n",
    "    def make_prediction(self, image: np.ndarray, type_of_task: str) -> tuple:\n",
    "        \"\"\"\n",
    "        Function provide classification of incoming image\n",
    "        :param image: Cropped image with hallmark or letter\n",
    "        :param type_of_task: type of classification task ('hallmark' or 'letter')\n",
    "        :return: tuple with predicted label and confidence of prediction\n",
    "        \"\"\"\n",
    "\n",
    "        if type_of_task == 'Year':\n",
    "            start = time.time()\n",
    "            predicted_label = predict_year(image)\n",
    "            end = time.time()\n",
    "            print(f'Classification {type_of_task} inference time : {(end - start):.2f} seconds')\n",
    "            return predicted_label, 0\n",
    "        \n",
    "        if type_of_task == 'Letter':\n",
    "            model = self.letter_model\n",
    "            image_shape = self.config.letter_image_shape\n",
    "            labels = self.config.letters\n",
    "        elif type_of_task == 'Hallmark':\n",
    "            model = self.city_model\n",
    "            image_shape = self.config.hallmark_image_shape\n",
    "            labels = self.config.cities\n",
    "        elif type_of_task == 'Russian':\n",
    "            model = self.russian_model\n",
    "            image_shape = self.config.hallmark_image_shape\n",
    "            labels = self.config.russian\n",
    "               \n",
    "                        \n",
    "        print(type_of_task)\n",
    "        image = image_to_gray(image)\n",
    "        image = cv2.resize(image, image_shape)\n",
    "        image = torch.tensor(image / 255).float().permute(2, 0, 1).unsqueeze(0).to(self.device)\n",
    "\n",
    "        start = time.time()\n",
    "        prediction = model(image).squeeze().detach().cpu()\n",
    "        end = time.time()\n",
    "\n",
    "        print(f'Classification {type_of_task} inference time : {(end - start):.2f} seconds')\n",
    "\n",
    "        predicted_class = prediction.argmax()\n",
    "        predicted_label = labels[predicted_class]\n",
    "        confidence = prediction.sigmoid()[predicted_class].item()\n",
    "\n",
    "        return predicted_label, confidence\n",
    "\n",
    "    def process_image(self, image: np.ndarray) -> tuple:\n",
    "        \"\"\"\n",
    "        Function process image of silverware. (detects the hallmark and classify the town and letter)\n",
    "        :param image: image for hallmark analysis\n",
    "        :return: dictionary with keys Detection classes and values tuple of classification classes\n",
    "        \"\"\"\n",
    "        image = cv2.resize(image, (416, 416))\n",
    "        \n",
    "        start = time.time()\n",
    "        classes, scores, boxes = self.detection_model.detect(image, self.detection_threshold, self.nms_threshold)\n",
    "        end = time.time()\n",
    "\n",
    "        print(f'Detection inference time : {(end - start):.2f} seconds')\n",
    "\n",
    "        analysis_results = {}\n",
    "        print('classes', classes, 'len', len(classes))\n",
    "        for (class_id, score, box) in zip(classes, scores, boxes):\n",
    "            color = self.colors[int(class_id)]\n",
    "\n",
    "            x_left, y_top, x_right, y_bottom = box[0], box[1], box[0] + box[2], box[1] + box[3]\n",
    "            image_hallmark = image[y_top:y_bottom, x_left:x_right]\n",
    "\n",
    "            print('class_id', class_id)\n",
    "            if class_id == 0:\n",
    "                label = f\"{self.config.class_names[class_id]}: {float(score):.2f}\"\n",
    "                text_position = (box[0]-5, box[1] - 5)\n",
    "                cv2.rectangle(image, box, color, 1)\n",
    "                cv2.putText(image, label, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "                return image, analysis_results\n",
    "            \n",
    "            \n",
    "            classification_label, confidence = self.make_prediction(image_hallmark,\n",
    "                                                                    self.config.class_names[\n",
    "                                                                        class_id])\n",
    "            analysis_results[self.config.class_names[class_id]] = (classification_label, confidence)\n",
    "\n",
    "            if class_id == 4:\n",
    "                label = f'{self.config.class_names[class_id]}: {float(score):.2f}, {classification_label}'\n",
    "            else:\n",
    "                label = f'{self.config.class_names[class_id]}: {float(score):.2f}, {classification_label}: {confidence:.2f}'\n",
    "\n",
    "            if class_id == 2 or class_id == 4:\n",
    "                text_position = (box[0], box[1] + box[2] + 10) \n",
    "            else:\n",
    "                text_position = (box[0] - 5, box[1] - 5)\n",
    "\n",
    "            cv2.rectangle(image, box, color, 1)\n",
    "            cv2.putText(image, label, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        return image, analysis_results\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser(description='Process some arguments')\n",
    "# #     parser.add_argument('--image', type=str, required=False, default='TestImages/0.jpg', help='Path to image')\n",
    "\n",
    "# #     args = parser.parse_args()\n",
    "# #     image_path = args.image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_hallmark(image_path, save_path):\n",
    "    \n",
    "    cfg = Configuration()\n",
    "    analyser = HallmarkAnalyser(cfg)\n",
    "\n",
    "    image_input = cv2.imread(image_path)\n",
    "    assert image_input is not None, \"Image not found\"\n",
    "\n",
    "    # Change BGR to RGB\n",
    "    image_input = cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB)\n",
    "    image_output, results = analyser.process_image(image_input)\n",
    "\n",
    "    # Print results of models\n",
    "    f = open(f\"{save_path}.txt\", \"w\")\n",
    "    for key in results.keys():\n",
    "        f.write(f\"{key} : {results[key][0]} - {results[key][1]}\" + \"\\n\")\n",
    "        print(f\"{key} : {results[key][0]} - {results[key][1]}\")\n",
    "\n",
    "    try:\n",
    "        url = \"https://silvermakersmarks.co.uk/Dates/{}/Date%20Letters%20{}.html\".format(\n",
    "            results['Hallmark'][0], results['Letter'][0])\n",
    "        f.write(url)\n",
    "        print(url)\n",
    "    except:\n",
    "        pass\n",
    "    f.close()\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image_output)\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection inference time : 0.95 seconds\n",
      "classes [3 4] len 2\n",
      "class_id 3\n",
      "Russian\n",
      "Classification Russian inference time : 0.07 seconds\n"
     ]
    }
   ],
   "source": [
    "path = 'TestImages'\n",
    "for file in os.listdir(path):\n",
    "    if file == '.ipynb_checkpoints': continue\n",
    "    recognize_hallmark(f'{path}/{file}', f'Detections/{file}')\n",
    "    print(\"_\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
